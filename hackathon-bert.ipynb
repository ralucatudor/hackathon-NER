{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-hypothetical",
   "metadata": {},
   "source": [
    "# 2nd try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mathematical-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "attempted-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = \"data/train.json\"\n",
    "\n",
    "with open(TRAIN_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automatic-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12330"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "right-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ner_tags', 'ner_ids', 'tokens', 'space_after'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caroline-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE_PATH = \"data/test.json\"\n",
    "\n",
    "with open(TEST_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "executive-protein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2421"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intelligent-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG2ID_FILE_PATH = \"data/tag_to_id.json\"\n",
    "\n",
    "with open(TAG2ID_FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    tag2id = json.load(f)\n",
    "# tag2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-pearl",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "complete-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [{'tokens' : data['tokens'], 'space_after' : data['space_after']} for data in train_data]\n",
    "y = [{'ner_ids' : data['ner_ids'], 'ner_tags' : data['ner_tags']} for data in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exempt-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [{'tokens' : data['tokens'], 'space_after' : data['space_after']} for data in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "arctic-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-native",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-theta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collectible-pierce",
   "metadata": {},
   "source": [
    "## Apply Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stuffed-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Neural Networks\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW # Transformers\n",
    "from sklearn.manifold import TSNE # Data projection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "duplicate-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS_PER_ENTRY = max([len(data['tokens']) for data in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "quarterly-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTransformer(Dataset):\n",
    "    def __init__(self, X, y, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.X[idx]\n",
    "        labels = self.y[idx]\n",
    "        \n",
    "        # Remove cedilla diacritics as suggested in\n",
    "        # https://huggingface.co/dumitrescustefan/bert-base-romanian-uncased-v1\n",
    "        tokens = [\n",
    "            token.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\") \n",
    "            for token in tokens\n",
    "        ]\n",
    "        print(tokens)\n",
    "        text_tensor = torch.tensor(self.tokenizer.convert_tokens_to_ids(tokens))\n",
    "        print(text_tensor)\n",
    "        print('shape',text_tensor.shape)\n",
    "        padder = torch.zeros(MAX_TOKENS_PER_ENTRY - len(tokens))\n",
    "        text_tensor = torch.cat([text_tensor, padder])\n",
    "        print(text_tensor.shape)\n",
    "        \n",
    "        return text_tensor, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "threatened-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"dumitrescustefan/bert-base-romanian-uncased-v1\", do_lower_case=False)\n",
    "# TODO INCEARCA SI CU True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "taken-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [data['tokens'] for data in train_data]\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "rough-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [data['ner_ids'] for data in train_data]\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "equipped-delight",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_SingleProcessDataLoaderIter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-003314d822d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# iter = next(iter(train_dataloader))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# data, label = next(iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_SingleProcessDataLoaderIter' object is not callable"
     ]
    }
   ],
   "source": [
    "ds_train = DatasetTransformer(X_train, y_train, tokenizer)\n",
    "ds_val = DatasetTransformer(X_validate, y_validate, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    ds_train, \n",
    "    sampler=RandomSampler(ds_train), \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ds_val, \n",
    "    sampler=SequentialSampler(ds_val), \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# iter = next(iter(train_dataloader))\n",
    "# print(iter)\n",
    "iter = iter(train_dataloader)\n",
    "print(iter.next())\n",
    "# data, label = next(iter)\n",
    "# print(data.shape)\n",
    "# print(data)\n",
    "\n",
    "# todo preda baga num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "stock-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, in_dim=768, no_classes=2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Get the romanian Transformer from the huggingface server\n",
    "        self.transformer = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\")\n",
    "        # Add a linear layer for classification\n",
    "        self.fc1 = nn.Linear(in_dim, no_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.squeeze(1)\n",
    "        # Get output from Transformer.\n",
    "        # We want the special [CLS] representation ([:,0,:]) from the last layer ([0]) \n",
    "        out = self.transformer(out)[0][:,0,:]\n",
    "        # We usually add dropout before the final classification layer when using a Transformer\n",
    "        out = F.dropout(out, p=0.1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-negative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-amplifier",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
